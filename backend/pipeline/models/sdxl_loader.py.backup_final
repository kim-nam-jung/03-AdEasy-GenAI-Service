"""
SDXL Loader with IP-Adapter and Multi-ControlNet Support
- SDXL 1.0 Base Model
- IP-Adapter for color/texture consistency
- Multi-ControlNet (SoftEdge + Depth) for shape guidance

[FIXED] ì£¼ìš” ìˆ˜ì •ì‚¬í•­:
1. VAE ë¡œì»¬ ê²½ë¡œ ê²€ì¦ ì¶”ê°€
2. generate_with_ip_adapter: control_imagesë¥¼ PIL Image ë¦¬ìŠ¤íŠ¸ë¡œ ë°›ë„ë¡ ë³€ê²½
3. controlnet_conditioning_scale: dict ë˜ëŠ” list ëª¨ë‘ ì§€ì›
4. ControlNet ëª¨ë¸ ê²½ë¡œ ìˆ˜ì • (SargeZT SoftEdge)
5. MultiControlNetModel ë˜í•‘ ì¶”ê°€
6. IP-Adapter ë¡œë”© ì²´í¬ ê°œì„ 
7. âœ… [NEW] CLIPVisionModelWithProjection ëª…ì‹œì  ë¡œë”© (ê²½ë¡œ ë¬¸ì œ í•´ê²°)
"""

import os
import torch
from diffusers import (
    StableDiffusionXLPipeline,
    ControlNetModel,
    StableDiffusionXLControlNetPipeline,
    AutoencoderKL
)
from diffusers.utils import load_image
from diffusers import MultiControlNetModel
from transformers import CLIPVisionModelWithProjection  # âœ… ì¶”ê°€
from PIL import Image
from pathlib import Path
from typing import List, Union, Dict, Optional

from common.logger import get_logger

logger = get_logger("SDXL_Loader")


class SDXLLoader:
    def __init__(self, device="cuda", dtype=torch.float16):
        """
        SDXL ë¡œë” ì´ˆê¸°í™”
        
        Args:
            device: 'cuda' or 'cpu'
            dtype: torch.float16 (ê¶Œì¥) or torch.float32
        """
        self.device = device
        self.dtype = dtype
        self.pipeline = None
        self.controlnet = None  # âœ… MultiControlNetModel ì €ì¥ìš©
        self.ip_adapter_loaded = False  # âœ… IP-Adapter ë¡œë”© ìƒíƒœ
        
        # ëª¨ë¸ ê²½ë¡œ (ë¡œì»¬ models/ ë””ë ‰í† ë¦¬ ì‚¬ìš©)
        repo_root = Path(__file__).resolve().parents[2]  # ADEASY_SHORTS root
        self.model_id = str(repo_root / "models" / "SDXL-1.0")
        self.vae_path = str(repo_root / "models" / "SDXL-1.0" / "vae")
        
        # âœ… [FIXED] ControlNet ëª¨ë¸ ê²½ë¡œ ìˆ˜ì •
        self.controlnet_models = {
            "softedge": "SargeZT/controlnet-sd-xl-1.0-softedge-dexined",  # âœ… ì˜¬ë°”ë¥¸ ê²½ë¡œ
            "depth": "diffusers/controlnet-depth-sdxl-1.0"
        }
        
        logger.info(f"ğŸ”§ SDXL Loader ì´ˆê¸°í™”: device={device}, dtype={dtype}")
        logger.info(f"ğŸ“‚ ë¡œì»¬ SDXL ê²½ë¡œ: {self.model_id}")
        logger.info(f"ğŸ“‚ VAE ê²½ë¡œ: {self.vae_path}")

    def load(self, enable_controlnet=True):
        """
        SDXL ëª¨ë¸ ë¡œë”©
        
        Args:
            enable_controlnet: ControlNet í™œì„±í™” ì—¬ë¶€
        """
        try:
            logger.info("ğŸ“¦ SDXL ëª¨ë¸ ë¡œë”© ì‹œì‘...")
            
            # 1. VAE ë¡œë”© (ë¡œì»¬ ê²½ë¡œ ì‚¬ìš©)
            logger.info("â³ VAE ë¡œë”© ì¤‘...")
            logger.info(f"   - ê²½ë¡œ: {self.vae_path}")
            
            # âœ… [FIXED] VAE ê²½ë¡œ ê²€ì¦ ê°•í™”
            if not os.path.exists(self.vae_path):
                raise FileNotFoundError(
                    f"âŒ VAE ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {self.vae_path}\n"
                    f"   ë‹¤ìŒ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”: {self.model_id}/vae/"
                )
            
            vae = AutoencoderKL.from_pretrained(
                self.vae_path,
                torch_dtype=self.dtype,
                use_safetensors=True
            )
            logger.info("âœ… VAE ë¡œë”© ì™„ë£Œ")
            
            # 2. ControlNet ë¡œë”© (ì„ íƒ)
            if enable_controlnet:
                logger.info("â³ ControlNet ë¡œë”© ì¤‘...")
                
                # âœ… SoftEdge ControlNet (ìˆ˜ì •ëœ ê²½ë¡œ)
                logger.info(f"   - SoftEdge: {self.controlnet_models['softedge']}")
                controlnet_softedge = ControlNetModel.from_pretrained(
                    self.controlnet_models["softedge"],
                    torch_dtype=self.dtype
                )
                logger.info("âœ… ControlNet SoftEdge ë¡œë”© ì™„ë£Œ")
                
                # âœ… Depth ControlNet
                logger.info(f"   - Depth: {self.controlnet_models['depth']}")
                controlnet_depth = ControlNetModel.from_pretrained(
                    self.controlnet_models["depth"],
                    torch_dtype=self.dtype
                )
                logger.info("âœ… ControlNet Depth ë¡œë”© ì™„ë£Œ")
                
                # âœ… [FIXED] MultiControlNetModel ë˜í•‘
                self.controlnet = MultiControlNetModel([controlnet_softedge, controlnet_depth])
                logger.info("âœ… MultiControlNetModel êµ¬ì„± ì™„ë£Œ (SoftEdge + Depth)")
                
                # 3. Multi-ControlNet íŒŒì´í”„ë¼ì¸
                logger.info("â³ SDXL + Multi-ControlNet íŒŒì´í”„ë¼ì¸ êµ¬ì„± ì¤‘...")
                self.pipeline = StableDiffusionXLControlNetPipeline.from_pretrained(
                    self.model_id,
                    vae=vae,
                    controlnet=self.controlnet,  # âœ… MultiControlNetModel ì „ë‹¬
                    torch_dtype=self.dtype,
                    use_safetensors=True
                )
            else:
                # 3-alt. ê¸°ë³¸ SDXL íŒŒì´í”„ë¼ì¸
                logger.info("â³ SDXL ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ êµ¬ì„± ì¤‘...")
                self.pipeline = StableDiffusionXLPipeline.from_pretrained(
                    self.model_id,
                    vae=vae,
                    torch_dtype=self.dtype,
                    use_safetensors=True
                )
            
            # 4. GPUë¡œ ì´ë™
            self.pipeline.to(self.device)
            
            # 5. ë©”ëª¨ë¦¬ ìµœì í™”
            self.pipeline.enable_model_cpu_offload()  # CPU Offload
            logger.info("âœ… CPU Offload í™œì„±í™”")
            
            logger.info("âœ… SDXL ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
            logger.info(f"ğŸ“Š VRAM ì‚¬ìš©ëŸ‰: ~{self._get_vram_usage():.2f}GB")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ SDXL ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False

    def generate(
        self,
        prompt: str,
        negative_prompt: str = None,
        control_image_softedge: str = None,
        control_image_depth: str = None,
        controlnet_conditioning_scale: dict = None,
        num_inference_steps: int = 30,
        guidance_scale: float = 7.5,
        width: int = 1024,
        height: int = 576,
        seed: int = None
    ):
        """
        SDXLë¡œ ì´ë¯¸ì§€ ìƒì„± (IP-Adapter ì—†ì´)
        
        Args:
            prompt: í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸
            negative_prompt: ë¶€ì • í”„ë¡¬í”„íŠ¸
            control_image_softedge: SoftEdge ì œì–´ ì´ë¯¸ì§€ ê²½ë¡œ
            control_image_depth: Depth ì œì–´ ì´ë¯¸ì§€ ê²½ë¡œ
            controlnet_conditioning_scale: ControlNet ê°•ë„ {"softedge": 0.5, "depth": 0.8}
            num_inference_steps: ìƒì„± ìŠ¤í… ìˆ˜ (30~50 ê¶Œì¥)
            guidance_scale: CFG Scale (7~9 ê¶Œì¥)
            width: ì´ë¯¸ì§€ ë„ˆë¹„ (8ì˜ ë°°ìˆ˜)
            height: ì´ë¯¸ì§€ ë†’ì´ (8ì˜ ë°°ìˆ˜)
            seed: ëœë¤ ì‹œë“œ (ì¬í˜„ì„±)
        
        Returns:
            PIL.Image: ìƒì„±ëœ ì´ë¯¸ì§€
        """
        if self.pipeline is None:
            raise RuntimeError("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load()ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
        
        try:
            logger.info(f"ğŸ¨ ì´ë¯¸ì§€ ìƒì„± ì‹œì‘: {width}x{height}")
            logger.info(f"ğŸ“ Prompt: {prompt[:100]}...")
            
            # Seed ì„¤ì •
            generator = None
            if seed is not None:
                generator = torch.Generator(device=self.device).manual_seed(seed)
                logger.info(f"ğŸ² Seed: {seed}")
            
            # ê¸°ë³¸ negative prompt
            if negative_prompt is None:
                negative_prompt = (
                    "blurry, low quality, distorted, deformed, ugly, bad anatomy, "
                    "watermark, text, signature, low resolution, pixelated"
                )
            
            # âœ… [FIXED] ControlNet ì´ë¯¸ì§€ ë¡œë”© (None ì²´í¬ ê°œì„ )
            control_images = []
            conditioning_scales = []
            
            # ê¸°ë³¸ ìŠ¤ì¼€ì¼ ì„¤ì •
            default_scales = {"softedge": 0.5, "depth": 0.8}
            if controlnet_conditioning_scale is None:
                controlnet_conditioning_scale = default_scales
            
            if control_image_softedge and os.path.exists(control_image_softedge):
                img = load_image(control_image_softedge).resize((width, height))
                control_images.append(img)
                conditioning_scales.append(
                    controlnet_conditioning_scale.get("softedge", 0.5)
                )
                logger.info(f"âœ… SoftEdge ì œì–´ ì´ë¯¸ì§€: {Path(control_image_softedge).name}")
            
            if control_image_depth and os.path.exists(control_image_depth):
                img = load_image(control_image_depth).resize((width, height))
                control_images.append(img)
                conditioning_scales.append(
                    controlnet_conditioning_scale.get("depth", 0.8)
                )
                logger.info(f"âœ… Depth ì œì–´ ì´ë¯¸ì§€: {Path(control_image_depth).name}")
            
            # ìƒì„± íŒŒë¼ë¯¸í„°
            generate_kwargs = {
                "prompt": prompt,
                "negative_prompt": negative_prompt,
                "num_inference_steps": num_inference_steps,
                "guidance_scale": guidance_scale,
                "width": width,
                "height": height,
                "generator": generator
            }
            
            # ControlNet ì‚¬ìš© ì‹œ
            if len(control_images) > 0:
                generate_kwargs["image"] = control_images
                generate_kwargs["controlnet_conditioning_scale"] = conditioning_scales
                logger.info(f"ğŸ® ControlNet í™œì„±í™”: {len(control_images)}ê°œ ì œì–´ ì´ë¯¸ì§€")
                logger.info(f"ğŸšï¸ Conditioning Scale: {conditioning_scales}")
                logger.info(f"ğŸ“‹ ìˆœì„œ: [SoftEdge, Depth]")  # âœ… ìˆœì„œ ëª…ì‹œ
            
            # ìƒì„± ì‹¤í–‰
            logger.info("â³ ìƒì„± ì¤‘...")
            output = self.pipeline(**generate_kwargs)
            image = output.images[0]
            
            logger.info("âœ… ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!")
            return image
            
        except Exception as e:
            logger.error(f"âŒ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            raise

    def generate_with_ip_adapter(
        self,
        prompt: str,
        ip_adapter_image: str,
        negative_prompt: str = None,
        control_images: Optional[List[Image.Image]] = None,
        controlnet_conditioning_scale: Union[List[float], Dict[str, float], None] = None,
        ip_adapter_scale: float = 0.6,
        num_inference_steps: int = 30,
        guidance_scale: float = 7.5,
        width: int = 704,
        height: int = 1280,
        seed: int = None
    ):
        """
        IP-Adapterë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ìƒì„± (ìƒ‰ìƒ ì¼ê´€ì„±)
        
        Args:
            prompt: í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸
            ip_adapter_image: ì°¸ì¡° ì´ë¯¸ì§€ ê²½ë¡œ (ì œí’ˆ ì›ë³¸)
            negative_prompt: ë¶€ì • í”„ë¡¬í”„íŠ¸
            control_images: ControlNet ì œì–´ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ [SoftEdge PIL, Depth PIL]
            controlnet_conditioning_scale: ControlNet ê°•ë„ (list [0.5, 0.8] ë˜ëŠ” dict)
            ip_adapter_scale: IP-Adapter ê°•ë„ (0.0~1.0)
            num_inference_steps: ìƒì„± ìŠ¤í… ìˆ˜
            guidance_scale: CFG Scale
            width: ì´ë¯¸ì§€ ë„ˆë¹„
            height: ì´ë¯¸ì§€ ë†’ì´
            seed: ëœë¤ ì‹œë“œ
        
        Returns:
            PIL.Image: ìƒì„±ëœ ì´ë¯¸ì§€
        """
        if self.pipeline is None:
            raise RuntimeError("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load()ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
        
        try:
            # âœ… [FIXED] IP-Adapter ë¡œë”© - Image Encoder ëª…ì‹œì  ë¡œë”©
            if not self.ip_adapter_loaded:
                logger.info("â³ IP-Adapter ë¡œë”© ì¤‘...")
                try:
                    # 1ï¸âƒ£ CLIP Vision Model ëª…ì‹œì  ë¡œë”©
                    logger.info("â³ CLIP Vision Model ë¡œë”© ì¤‘...")
                    image_encoder = CLIPVisionModelWithProjection.from_pretrained(
                        "laion/CLIP-ViT-H-14-laion2B-s32B-b79K",
                        torch_dtype=self.dtype
                    ).to(self.device)
                    logger.info("âœ… CLIP Vision Model ë¡œë”© ì™„ë£Œ")
                    
                    # 2ï¸âƒ£ IP-Adapter ê°€ì¤‘ì¹˜ ë¡œë”© (Image Encoder ì§ì ‘ ì „ë‹¬)
                    logger.info("â³ IP-Adapter ê°€ì¤‘ì¹˜ ë¡œë”© ì¤‘...")
                    self.pipeline.load_ip_adapter(
                        "h94/IP-Adapter",
                        subfolder="sdxl_models",
                        weight_name="ip-adapter_sdxl.bin",
                        image_encoder=image_encoder  # âœ… ëª…ì‹œì  ì „ë‹¬
                    )
                    self.ip_adapter_loaded = True
                    logger.info("âœ… IP-Adapter ë¡œë”© ì™„ë£Œ")
                except Exception as e:
                    logger.error(f"âŒ IP-Adapter ë¡œë”© ì‹¤íŒ¨: {e}")
                    raise
            
            # IP-Adapter ì´ë¯¸ì§€ ë¡œë”©
            ip_image = load_image(ip_adapter_image).resize((width, height))
            logger.info(f"ğŸ¨ IP-Adapter ì°¸ì¡° ì´ë¯¸ì§€: {Path(ip_adapter_image).name}")
            logger.info(f"ğŸšï¸ IP-Adapter Scale: {ip_adapter_scale}")
            
            # IP-Adapter ì„¤ì •
            self.pipeline.set_ip_adapter_scale(ip_adapter_scale)
            
            logger.info(f"ğŸ¨ IP-Adapter ì´ë¯¸ì§€ ìƒì„± ì‹œì‘: {width}x{height}")
            logger.info(f"ğŸ“ Prompt: {prompt[:100]}...")
            
            # Seed ì„¤ì •
            generator = None
            if seed is not None:
                generator = torch.Generator(device=self.device).manual_seed(seed)
                logger.info(f"ğŸ² Seed: {seed}")
            
            # ê¸°ë³¸ negative prompt
            if negative_prompt is None:
                negative_prompt = (
                    "blurry, low quality, distorted, deformed, ugly, bad anatomy, "
                    "watermark, text, signature, low resolution, pixelated, "
                    "color change, pattern distortion, extra clothing, logo change"
                )
            
            # âœ… [FIXED] ControlNet ì´ë¯¸ì§€ ì²˜ë¦¬
            conditioning_scales = []
            
            if control_images is not None and len(control_images) > 0:
                logger.info(f"ğŸ® ControlNet í™œì„±í™”: {len(control_images)}ê°œ ì œì–´ ì´ë¯¸ì§€")
                
                # âœ… [FIXED] controlnet_conditioning_scale ì²˜ë¦¬
                if isinstance(controlnet_conditioning_scale, list):
                    conditioning_scales = controlnet_conditioning_scale
                    logger.info(f"ğŸšï¸ Conditioning Scale (list): {conditioning_scales}")
                
                elif isinstance(controlnet_conditioning_scale, dict):
                    conditioning_scales = [
                        controlnet_conditioning_scale.get("softedge", 0.5),
                        controlnet_conditioning_scale.get("depth", 0.8)
                    ]
                    logger.info(f"ğŸšï¸ Conditioning Scale (dict): {conditioning_scales}")
                
                else:
                    conditioning_scales = [0.5, 0.8]
                    logger.info(f"ğŸšï¸ Conditioning Scale (default): {conditioning_scales}")
                
                # âœ… ì œì–´ ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ
                control_images_resized = []
                for idx, img in enumerate(control_images):
                    if img.size != (width, height):
                        logger.info(f"   - ì œì–´ ì´ë¯¸ì§€ {idx+1} ë¦¬ì‚¬ì´ì¦ˆ: {img.size} â†’ {(width, height)}")
                        control_images_resized.append(img.resize((width, height)))
                    else:
                        control_images_resized.append(img)
                
                control_images = control_images_resized
                logger.info(f"ğŸ“‹ ControlNet ìˆœì„œ: [SoftEdge, Depth]")
            
            # ìƒì„± íŒŒë¼ë¯¸í„°
            generate_kwargs = {
                "prompt": prompt,
                "negative_prompt": negative_prompt,
                "ip_adapter_image": ip_image,
                "num_inference_steps": num_inference_steps,
                "guidance_scale": guidance_scale,
                "width": width,
                "height": height,
                "generator": generator
            }
            
            # ControlNet ì‚¬ìš© ì‹œ
            if control_images is not None and len(control_images) > 0:
                generate_kwargs["image"] = control_images
                generate_kwargs["controlnet_conditioning_scale"] = conditioning_scales
            
            # ìƒì„± ì‹¤í–‰
            logger.info("â³ ìƒì„± ì¤‘ (IP-Adapter + Multi-ControlNet)...")
            output = self.pipeline(**generate_kwargs)
            image = output.images[0]
            
            logger.info("âœ… IP-Adapter ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!")
            return image
            
        except Exception as e:
            logger.error(f"âŒ IP-Adapter ìƒì„± ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            raise

    def _get_vram_usage(self):
        """í˜„ì¬ VRAM ì‚¬ìš©ëŸ‰ (GB)"""
        if torch.cuda.is_available():
            return torch.cuda.memory_allocated() / 1024**3
        return 0.0

    def unload(self):
        """ëª¨ë¸ ì–¸ë¡œë“œ (ë©”ëª¨ë¦¬ í•´ì œ)"""
        if self.pipeline is not None:
            del self.pipeline
            self.pipeline = None
        
        if self.controlnet is not None:
            del self.controlnet
            self.controlnet = None
        
        self.ip_adapter_loaded = False
        
        torch.cuda.empty_cache()
        logger.info("ğŸ—‘ï¸ SDXL ëª¨ë¸ ì–¸ë¡œë“œ ì™„ë£Œ")


# ===== ì‹±ê¸€í†¤ íŒ¨í„´ (ì „ì—­ ì¸ìŠ¤í„´ìŠ¤) =====
_sdxl_loader_instance = None


def get_sdxl_loader(device="cuda", dtype=torch.float16):
    """
    SDXL ë¡œë” ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜
    
    Returns:
        SDXLLoader: SDXL ë¡œë” ì¸ìŠ¤í„´ìŠ¤
    """
    global _sdxl_loader_instance
    
    if _sdxl_loader_instance is None:
        _sdxl_loader_instance = SDXLLoader(device=device, dtype=dtype)
    
    return _sdxl_loader_instance


# ===== í…ŒìŠ¤íŠ¸ ì½”ë“œ =====
if __name__ == "__main__":
    import sys
    
    # í…ŒìŠ¤íŠ¸: SDXL ëª¨ë¸ ë¡œë”©
    loader = get_sdxl_loader()
    
    if loader.load(enable_controlnet=True):
        print("âœ… SDXL ë¡œë”© ì„±ê³µ!")
        
        # ê°„ë‹¨í•œ ìƒì„± í…ŒìŠ¤íŠ¸
        test_prompt = "a professional product photo of a delicious burger, studio lighting, high quality"
        
        try:
            image = loader.generate(
                prompt=test_prompt,
                width=1024,
                height=576,
                num_inference_steps=20,
                seed=42
            )
            
            # ì €ì¥
            output_path = "test_sdxl_output.png"
            image.save(output_path)
            print(f"âœ… í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ: {output_path}")
            
        except Exception as e:
            print(f"âŒ ìƒì„± ì‹¤íŒ¨: {e}")
    else:
        print("âŒ SDXL ë¡œë”© ì‹¤íŒ¨")
        sys.exit(1)
