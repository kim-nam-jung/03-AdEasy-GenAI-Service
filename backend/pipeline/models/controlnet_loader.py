"""
ControlNet ì œì–´ë§µ ìƒì„±ê¸° (Step 3ìš©)

âœ¨ í•µì‹¬ ê¸°ëŠ¥:
- Canny Edge Detection (OpenCV)
- Depth Map ìƒì„± (MiDaS v3.1 DPT-Large)
- ë©€í‹° ì œì–´ë§µ ì§€ì›
- ë©”ëª¨ë¦¬ ìµœì í™” (8bit ì–‘ìí™”)
- GPU ìºì‹œ ê´€ë¦¬
"""

import cv2
import numpy as np
import torch
from PIL import Image
from pathlib import Path
from typing import Literal, Optional, Tuple
import time

class ControlNetProcessor:
    """
    ControlNet ì œì–´ë§µ ìƒì„± í”„ë¡œì„¸ì„œ
    
    ì§€ì› ë°©ë²•:
    - canny: Edge detection
    - depth: Depth map (MiDaS)
    """
    
    def __init__(
        self,
        device: str = "cuda",
        use_8bit: bool = True
    ):
        """
        Args:
            device: 'cuda' or 'cpu'
            use_8bit: 8bit ì–‘ìí™” ì‚¬ìš© ì—¬ë¶€
        """
        self.device = device
        self.use_8bit = use_8bit
        self.depth_model = None
        self.depth_transform = None
        
        print(f"ğŸ¨ ControlNetProcessor initialized")
        print(f"   Device: {device}")
        print(f"   8bit quantization: {use_8bit}")
    
    def load_depth_model(self):
        """MiDaS Depth ëª¨ë¸ ë¡œë”© (í•„ìš”ì‹œ)"""
        if self.depth_model is not None:
            return
        
        print("ğŸ“¦ Loading MiDaS Depth model...")
        start_time = time.time()
        
        try:
            # MiDaS v3.1 DPT-Large ëª¨ë¸
            model_type = "DPT_Large"
            self.depth_model = torch.hub.load(
                "intel-isl/MiDaS",
                model_type,
                trust_repo=True
            )
            
            # 8bit ì–‘ìí™”
            if self.use_8bit and self.device == "cuda":
                self.depth_model = self.depth_model.half()
            
            self.depth_model.to(self.device)
            self.depth_model.eval()
            
            # Transform ë¡œë”©
            midas_transforms = torch.hub.load("intel-isl/MiDaS", "transforms")
            self.depth_transform = midas_transforms.dpt_transform
            
            elapsed = time.time() - start_time
            print(f"âœ… MiDaS model loaded in {elapsed:.1f}s")
            
            if self.device == "cuda":
                memory_gb = torch.cuda.memory_allocated() / 1024**3
                print(f"   GPU Memory: {memory_gb:.2f} GB")
        
        except Exception as e:
            print(f"âŒ Failed to load MiDaS: {e}")
            raise
    
    def generate_canny(
        self,
        image: Image.Image,
        low_threshold: int = 100,
        high_threshold: int = 200
    ) -> Image.Image:
        """
        Canny Edge Detection
        
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€
            low_threshold: Canny low threshold
            high_threshold: Canny high threshold
        
        Returns:
            Canny edge map (PIL Image)
        """
        # PIL â†’ NumPy
        img_np = np.array(image)
        
        # RGB â†’ Grayscale
        if len(img_np.shape) == 3:
            gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)
        else:
            gray = img_np
        
        # Canny Edge Detection
        edges = cv2.Canny(gray, low_threshold, high_threshold)
        
        # 3ì±„ë„ ë³€í™˜ (ControlNet ì…ë ¥ í˜•ì‹)
        edges_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)
        
        return Image.fromarray(edges_rgb)
    
    def generate_depth(
        self,
        image: Image.Image
    ) -> Image.Image:
        """
        Depth Map ìƒì„± (MiDaS)
        
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€
        
        Returns:
            Depth map (PIL Image, 0-255 ë²”ìœ„)
        """
        # ëª¨ë¸ ë¡œë”© (lazy loading)
        self.load_depth_model()
        
        # PIL â†’ NumPy
        img_np = np.array(image)
        
        # Transform ì ìš©
        input_batch = self.depth_transform(img_np).to(self.device)
        
        if self.use_8bit and self.device == "cuda":
            input_batch = input_batch.half()
        
        # Depth ì˜ˆì¸¡
        with torch.no_grad():
            prediction = self.depth_model(input_batch)
            
            # ì›ë³¸ í•´ìƒë„ë¡œ ë¦¬ìƒ˜í”Œë§
            prediction = torch.nn.functional.interpolate(
                prediction.unsqueeze(1),
                size=img_np.shape[:2],
                mode="bicubic",
                align_corners=False,
            ).squeeze()
        
        # Tensor â†’ NumPy
        depth_map = prediction.cpu().numpy()
        
        # ì •ê·œí™” (0-255)
        depth_map = (depth_map - depth_map.min()) / (depth_map.max() - depth_map.min())
        depth_map = (depth_map * 255).astype(np.uint8)
        
        # 3ì±„ë„ ë³€í™˜
        depth_rgb = cv2.cvtColor(depth_map, cv2.COLOR_GRAY2RGB)
        
        return Image.fromarray(depth_rgb)
    
    def generate_control_map(
        self,
        image_path: Path,
        method: Literal["canny", "depth"] = "canny",
        output_path: Optional[Path] = None,
        **kwargs
    ) -> Image.Image:
        """
        ì œì–´ë§µ ìƒì„± (í†µí•© ì¸í„°í˜ì´ìŠ¤)
        
        Args:
            image_path: ì…ë ¥ ì´ë¯¸ì§€ ê²½ë¡œ
            method: 'canny' or 'depth'
            output_path: ì €ì¥ ê²½ë¡œ (optional)
            **kwargs: ì¶”ê°€ íŒŒë¼ë¯¸í„° (low_threshold, high_threshold ë“±)
        
        Returns:
            ì œì–´ë§µ ì´ë¯¸ì§€
        """
        # ì´ë¯¸ì§€ ë¡œë”©
        image = Image.open(image_path).convert('RGB')
        
        print(f"ğŸ¨ Generating {method.upper()} control map...")
        print(f"   Input: {image_path.name} ({image.size[0]}x{image.size[1]})")
        
        start_time = time.time()
        
        # ì œì–´ë§µ ìƒì„±
        if method == "canny":
            control_map = self.generate_canny(
                image,
                low_threshold=kwargs.get('low_threshold', 100),
                high_threshold=kwargs.get('high_threshold', 200)
            )
        elif method == "depth":
            control_map = self.generate_depth(image)
        else:
            raise ValueError(f"Unknown method: {method}")
        
        elapsed = time.time() - start_time
        print(f"âœ… Control map generated in {elapsed:.1f}s")
        
        # ì €ì¥
        if output_path:
            control_map.save(output_path)
            print(f"   Saved: {output_path.name}")
        
        return control_map
    
    def unload(self):
        """ë©”ëª¨ë¦¬ í•´ì œ"""
        if self.depth_model is not None:
            del self.depth_model
            self.depth_model = None
            self.depth_transform = None
        
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        print("ğŸ—‘ï¸  ControlNet processor unloaded")


# ==================== ì‚¬ìš© ì˜ˆì‹œ ====================
if __name__ == "__main__":
    import sys
    
    # í…ŒìŠ¤íŠ¸ìš©
    processor = ControlNetProcessor(device="cuda", use_8bit=True)
    
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
    test_img = Image.new('RGB', (512, 512), (255, 255, 255))
    # ì¤‘ì•™ì— ì‚¬ê°í˜• ê·¸ë¦¬ê¸°
    import numpy as np
    arr = np.array(test_img)
    arr[150:350, 150:350] = [0, 0, 255]
    test_img = Image.fromarray(arr)
    test_img.save("/tmp/test_input.png")
    
    # Canny í…ŒìŠ¤íŠ¸
    print("\n=== Canny Edge Test ===")
    canny_map = processor.generate_control_map(
        Path("/tmp/test_input.png"),
        method="canny",
        output_path=Path("/tmp/test_canny.png")
    )
    
    # Depth í…ŒìŠ¤íŠ¸
    print("\n=== Depth Map Test ===")
    depth_map = processor.generate_control_map(
        Path("/tmp/test_input.png"),
        method="depth",
        output_path=Path("/tmp/test_depth.png")
    )
    
    processor.unload()
    
    print("\nâœ… All tests completed!")
    print(f"   Canny: /tmp/test_canny.png")
    print(f"   Depth: /tmp/test_depth.png")