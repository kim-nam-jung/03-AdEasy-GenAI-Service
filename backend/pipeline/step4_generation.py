# pipeline/step4_generation.py
"""
Step 4: Keyframe Generation Pipeline
SDXL + ControlNet + IP-Adapterë¥¼ ì‚¬ìš©í•œ Sceneë³„ í‚¤í”„ë ˆìž„ ìƒì„±

âœ¨ í•µì‹¬ ê¸°ëŠ¥:
- SDXL 1.0 Base + Multi-ControlNet (SoftEdge + Depth)
- Sceneë³„ Start/End Frame ìƒì„± (3 Scene Ã— 2 = 6ìž¥)
- 704Ã—1280 í•´ìƒë„ (ì„¸ë¡œí˜•)
- IP-Adapter: ì œí’ˆ ì¼ê´€ì„± ìœ ì§€
- ì™„ì „ ë¡œì»¬ ì‹¤í–‰ (L4 24GB GPU)

[FIXED] ì£¼ìš” ìˆ˜ì •ì‚¬í•­:
1. generate_with_ip_adapter í˜¸ì¶œ ì‹œ íŒŒë¼ë¯¸í„° ì´ë¦„ ìˆ˜ì • (ip_adapter_image)
2. control_imagesë¥¼ PIL Image ë¦¬ìŠ¤íŠ¸ë¡œ ì „ë‹¬
3. controlnet_conditioning_scaleì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì „ë‹¬
"""

import os
import json
import logging
from pathlib import Path
from typing import Dict, List, Optional
from PIL import Image
import torch

# ===== ì˜¬ë°”ë¥¸ import =====
from pipeline.models.sdxl_loader import get_sdxl_loader
from common.paths import TaskPaths
from common.config import Config
from common.logger import TaskLogger

logger = logging.getLogger("Step4_KeyframeGenerator")
logger.setLevel(logging.INFO)


class Step4_KeyframeGenerator:
    """
    Step 4: í‚¤í”„ë ˆìž„ ìƒì„±ê¸°
    
    ìž…ë ¥:
    - product_image: Step 0ì˜ ëˆ„ë¼ ì´ë¯¸ì§€ (IP-Adapterìš©)
    - visual_dna: Step 1ì˜ ì œí’ˆ íŠ¹ì§• (í”„ë¡¬í”„íŠ¸ ì¦ê°•ìš©)
    - scenario: Step 2ì˜ ì‹œë‚˜ë¦¬ì˜¤ (3ê°œ Scene)
    - control_maps: Step 3ì˜ ì œì–´ë§µ (softedge, depth, mask, bbox)
    
    ì¶œë ¥:
    - 6ê°œ í‚¤í”„ë ˆìž„ (Sceneë³„ Start/End Frame)
    """
    
    def __init__(self):
        self.loader = None  # SDXL LoaderëŠ” ì²« ì‹¤í–‰ ì‹œ ë¡œë“œ
        logger.info("âœ… Step4_KeyframeGenerator ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _load_model(self):
        """SDXL ëª¨ë¸ ë¡œë”© (ìµœì´ˆ 1íšŒë§Œ)"""
        if self.loader is None:
            logger.info("ðŸ“¦ SDXL ëª¨ë¸ ë¡œë”© ì¤‘... (ìµœì´ˆ 1íšŒ 30ì´ˆ ì†Œìš”)")
            
            self.loader = get_sdxl_loader()
            
            # [FIXED] enable_cpu_offload ì œê±°
            success = self.loader.load(enable_controlnet=True)
            
            if not success:
                raise RuntimeError("âŒ SDXL ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨!")
            
            logger.info("âœ… SDXL ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
    
    def generate_keyframes(
        self,
        product_image: str,
        visual_dna: str,
        scenario: Dict,
        control_maps: Dict,
        output_dir: str,
        num_inference_steps: int = 30,
        guidance_scale: float = 7.5,
        controlnet_scale: List[float] = [0.5, 0.8],
        seed: Optional[int] = None
    ) -> Dict[str, str]:
        """
        í‚¤í”„ë ˆìž„ ìƒì„± ë©”ì¸ í•¨ìˆ˜
        """
        try:
            logger.info("ðŸŽ¬ [Step 4] í‚¤í”„ë ˆìž„ ìƒì„± ì‹œìž‘...")
            logger.info(f"   - ìž…ë ¥ ì´ë¯¸ì§€: {Path(product_image).name}")
            logger.info(f"   - Scene ìˆ˜: {len(scenario.get('scenes', []))}")
            logger.info(f"   - Inference Steps: {num_inference_steps}")
            logger.info(f"   - Guidance Scale: {guidance_scale}")
            logger.info(f"   - ControlNet Scale: {controlnet_scale}")
            
            # 1) ëª¨ë¸ ë¡œë”©
            self._load_model()
            
            # 2) ì œì–´ë§µ ë¡œë“œ [FIXED] PIL Image ë¦¬ìŠ¤íŠ¸ë¡œ ì¤€ë¹„
            softedge_path = control_maps.get('softedge_path')
            depth_path = control_maps.get('depth_path')
            
            control_images = None  # [FIXED] ê¸°ë³¸ê°’ None
            
            if not softedge_path or not depth_path:
                logger.warning("âš ï¸ SoftEdge ë˜ëŠ” Depth Mapì´ ì—†ìŠµë‹ˆë‹¤. ControlNet ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤.")
            else:
                logger.info(f"   - SoftEdge: {Path(softedge_path).name}")
                logger.info(f"   - Depth: {Path(depth_path).name}")
                
                # [FIXED] PIL Image ë¦¬ìŠ¤íŠ¸ë¡œ ë¡œë“œ
                softedge_img = Image.open(softedge_path).convert('RGB')
                depth_img = Image.open(depth_path).convert('RGB')
                control_images = [softedge_img, depth_img]
            
            # 3) ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs(output_dir, exist_ok=True)
            
            # 4) Sceneë³„ í‚¤í”„ë ˆìž„ ìƒì„±
            keyframes = {}
            scenes = scenario.get('scenes', [])
            
            for scene in scenes:
                scene_id = scene['scene_id']
                logger.info(f"\\n{'='*60}")
                logger.info(f"ðŸŽ¨ Scene {scene_id} í‚¤í”„ë ˆìž„ ìƒì„± ì¤‘...")
                logger.info(f"{'='*60}")
                
                # ===== Start Frame ìƒì„± =====
                logger.info(f"ðŸŽ¬ Scene {scene_id} - Start Frame")
                
                start_prompt = self._build_prompt(
                    scene, 
                    visual_dna, 
                    frame_type='start'
                )
                logger.info(f"   Prompt: {start_prompt[:80]}...")
                
                # [FIXED] íŒŒë¼ë¯¸í„° ì´ë¦„ ìˆ˜ì •: ip_adapter_image
                start_image = self.loader.generate_with_ip_adapter(
                    prompt=start_prompt,
                    ip_adapter_image=product_image,  # [FIXED] ì´ë¦„ ë³€ê²½
                    ip_adapter_scale=0.6,
                    negative_prompt="low quality, blurry, distorted, watermark, text, deformed",
                    width=704,
                    height=1280,
                    num_inference_steps=num_inference_steps,
                    guidance_scale=guidance_scale,
                    seed=seed + scene_id * 10 if seed else None,
                    control_images=control_images,  # [FIXED] PIL Image ë¦¬ìŠ¤íŠ¸
                    controlnet_conditioning_scale=controlnet_scale  # [FIXED] ë¦¬ìŠ¤íŠ¸ ì „ë‹¬
                )
                
                if start_image:
                    start_path = os.path.join(output_dir, f"scene{scene_id}_start.png")
                    start_image.save(start_path)
                    keyframes[f"scene{scene_id}_start"] = start_path
                    logger.info(f"   âœ… Start Frame ì €ìž¥: {Path(start_path).name}")
                else:
                    logger.error(f"   âŒ Start Frame ìƒì„± ì‹¤íŒ¨")
                
                # ===== End Frame ìƒì„± =====
                logger.info(f"ðŸŽ¬ Scene {scene_id} - End Frame")
                
                end_prompt = self._build_prompt(
                    scene, 
                    visual_dna, 
                    frame_type='end'
                )
                logger.info(f"   Prompt: {end_prompt[:80]}...")
                
                # [FIXED] íŒŒë¼ë¯¸í„° ì´ë¦„ ìˆ˜ì •: ip_adapter_image
                end_image = self.loader.generate_with_ip_adapter(
                    prompt=end_prompt,
                    ip_adapter_image=product_image,  # [FIXED] ì´ë¦„ ë³€ê²½
                    ip_adapter_scale=0.6,
                    negative_prompt="low quality, blurry, distorted, watermark, text, deformed",
                    width=704,
                    height=1280,
                    num_inference_steps=num_inference_steps,
                    guidance_scale=guidance_scale,
                    seed=seed + scene_id * 10 + 5 if seed else None,
                    control_images=control_images,  # [FIXED] PIL Image ë¦¬ìŠ¤íŠ¸
                    controlnet_conditioning_scale=controlnet_scale  # [FIXED] ë¦¬ìŠ¤íŠ¸ ì „ë‹¬
                )
                
                if end_image:
                    end_path = os.path.join(output_dir, f"scene{scene_id}_end.png")
                    end_image.save(end_path)
                    keyframes[f"scene{scene_id}_end"] = end_path
                    logger.info(f"   âœ… End Frame ì €ìž¥: {Path(end_path).name}")
                else:
                    logger.error(f"   âŒ End Frame ìƒì„± ì‹¤íŒ¨")
            
            logger.info(f"\\n{'='*60}")
            logger.info(f"âœ… [Step 4] ì™„ë£Œ: {len(keyframes)}/6 í‚¤í”„ë ˆìž„ ìƒì„±")
            logger.info(f"{'='*60}")
            
            return keyframes
        
        except Exception as e:
            logger.error(f"âŒ í‚¤í”„ë ˆìž„ ìƒì„± ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    def _build_prompt(self, scene: Dict, visual_dna: str, frame_type: str) -> str:
        """
        Scene ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        """
        description = scene.get('description', '')
        camera = scene.get('camera_movement', '')
        
        if frame_type == 'start':
            frame_desc = scene.get('start_frame_description', '')
        else:
            frame_desc = scene.get('end_frame_description', '')
        
        # í”„ë¡¬í”„íŠ¸ ì¡°í•©
        prompt = f"{description}. {frame_desc}. Camera movement: {camera}. Product features: {visual_dna}. Professional advertising photography, cinematic lighting, 4K quality, high detail."
        
        return prompt
    
    def unload(self):
        """ëª¨ë¸ ì–¸ë¡œë“œ (ë©”ëª¨ë¦¬ í•´ì œ)"""
        if self.loader:
            logger.info("ðŸ—‘ï¸ SDXL ëª¨ë¸ ì–¸ë¡œë“œ ì¤‘...")
            self.loader.unload()
            self.loader = None
            logger.info("âœ… ëª¨ë¸ ì–¸ë¡œë“œ ì™„ë£Œ")


# ==================== ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ====================
_step4_generator_instance = None

def get_step4_generator():
    """Step 4 Generator ì‹±ê¸€í†¤ ê°€ì ¸ì˜¤ê¸°"""
    global _step4_generator_instance
    if _step4_generator_instance is None:
        _step4_generator_instance = Step4_KeyframeGenerator()
    return _step4_generator_instance


# ==================== Adapter Function ====================
def step4_generation(
    task_id: str,
    paths: TaskPaths,
    logger: TaskLogger,
    cfg: Config,
    processed_images: list = None,
    visual_dna: str = "",
    scenario: dict = None,
    control_maps: dict = None, # Can be dict or list of dicts
    **kwargs
) -> dict:
    """
    Step 4 Adapter
    """
    # 1. Get main product image
    if not processed_images:
        raise ValueError("Step 4: No processed_images provided")
    product_image = processed_images[0]
    
    # Handle control_maps list
    c_maps = control_maps
    if isinstance(c_maps, list):
        if len(c_maps) > 0:
            c_maps = c_maps[0]
        else:
            c_maps = {}
    if c_maps is None:
        c_maps = {}

    # 3. Instantiate Generator
    generator = get_step4_generator() 
    
    output_dir = paths.data_dir / "step4_keyframes"
    
    # 4. Generate
    keyframes_map = generator.generate_keyframes(
        product_image=str(product_image),
        visual_dna=visual_dna,
        scenario=scenario,
        control_maps=c_maps,
        output_dir=str(output_dir)
        # Defaults for other params
    )
    
    # 5. Extract Start Frames for Step 5
    ordered_keyframes = []
    scenes = scenario.get('scenes', [])
    for scene in scenes:
        sid = scene['scene_id']
        key = f"scene{sid}_start" # Use Start frame for video gen
        if key in keyframes_map:
            ordered_keyframes.append(Path(keyframes_map[key]))
        else:
            logger.error(f"Missing keyframe for scene {sid}: {key}")
            
    return {
        "keyframes": ordered_keyframes,
    }
