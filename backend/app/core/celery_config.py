# backend/celery_config.py
"""
Celery ì„¤ì • ë° ì´ˆê¸°í™”
Redisë¥¼ ë¸Œë¡œì»¤/ë°±ì—”ë“œë¡œ ì‚¬ìš©
"""

from celery import Celery
from common.config import Config

# Config ë¡œë“œ
cfg = Config.load()

# Redis URL ê°€ì ¸ì˜¤ê¸°
# Resolve env var first (happens in Config.load)
redis_url = cfg.get('redis.url') or cfg.get('redis.default_url', 'redis://localhost:6379/0')

# Celery ì•± ìƒì„±
celery_app = Celery(
    'adeasy_shorts',
    broker=redis_url,
    backend=redis_url,
    include=['app.worker']  # tasks ëª¨ë“ˆ ìë™ ë¡œë“œ
)

# Celery ì„¤ì •
celery_app.conf.update(
    # íƒ€ì„ì¡´
    timezone='Asia/Seoul',
    enable_utc=True,
    
    # ê²°ê³¼ ì €ì¥ ì„¤ì •
    result_expires=86400,  # 24ì‹œê°„ í›„ ê²°ê³¼ ì‚­ì œ
    result_persistent=True,  # Redis ì¬ì‹œì‘ ì‹œì—ë„ ìœ ì§€
    
    # Task ì„¤ì •
    task_serializer='json',
    result_serializer='json',
    accept_content=['json'],
    task_track_started=True,  # Task ì‹œì‘ ì‹œì  ì¶”ì 
    task_time_limit=14400,  # 4ì‹œê°„ ìµœëŒ€ ì‹¤í–‰ ì‹œê°„
    task_soft_time_limit=13800,  # 3ì‹œê°„ 50ë¶„ ì†Œí”„íŠ¸ íƒ€ì„ì•„ì›ƒ
    
    # Worker ì„¤ì •
    worker_prefetch_multiplier=1,  # í•œ ë²ˆì— 1ê°œ Taskë§Œ ê°€ì ¸ì˜¤ê¸° (GPU ì‘ì—…ìš©)
    worker_max_tasks_per_child=50,  # 50ê°œ ì‘ì—… í›„ ì›Œì»¤ ì¬ì‹œì‘ (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€)
    
    # ë¡œê·¸
    worker_log_format='[%(asctime)s: %(levelname)s/%(processName)s] %(message)s',
    worker_task_log_format='[%(asctime)s: %(levelname)s/%(processName)s][%(task_name)s(%(task_id)s)] %(message)s',
)

# ì„¤ì • í™•ì¸ìš©
if __name__ == '__main__':
    print("ğŸ”§ Celery Config:")
    print(f"   Broker: {celery_app.conf.broker_url}")
    print(f"   Backend: {celery_app.conf.result_backend}")
    print(f"   Timezone: {celery_app.conf.timezone}")
